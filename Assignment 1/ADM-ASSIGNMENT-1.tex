% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Advanced Data Mining and Predictive Analytics},
  pdfauthor={Shivani Haridas Pitla},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Advanced Data Mining and Predictive Analytics}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Assignment 1}
\author{Shivani Haridas Pitla}
\date{2023-02-28}

\begin{document}
\maketitle

\textbf{QA1. What is the main purpose of regularization when training
predictive models?}

\emph{Answer:} Regularization is primarily used to avoid over-fitting
which happens when a model is overly complicated and fits the training
data too closely, leading to weak performance when applied to new data.
Regularization achieves this by adding a penalty term to the model's
objective function that discourages large coefficient values. This
penalty term can be adjusted by a hyper-parameter for example lambda in
Lasso and Ridge regression that regulates the level of regularization
applied to the model.Regularization can improve a model's generalization
performance by reducing its variance, at the cost of slightly increasing
its bias.

\textbf{QA2. What is the role of a loss function in a predictive model?
And name two common loss functions for regression models and two common
loss functions for classification models?}

\emph{Answer:} A loss function in a predictive model serves the purpose
of measuring the difference between the output that is predicted and the
actual output for a particular input. In other words, it evaluates how
accurate the model's predictions are.

There are two typical loss functions in regression models:

1.Mean Squared Error (MSE)

2.Mean Absolute Error (MAE)

Two typical loss functions used in classification models are:

1.Binary Cross-Entropy

2.Categorical Cross-Entropy

\textbf{QA3. Consider the following scenario. You are building a
classification model with many hyper parameters on a relatively small
data-set. You will see that the training error is extremely small. Can
you fully trust this model? Discuss the reason.}

\emph{Answer:} It is not advised to fully trust this model in the
mentioned case, when a classification model is developed with many
hyper-parameters on a small data-set and the training error is
incredibly minimal. This is due to a few factors like over-fitting lack
of generalization and need for cross validation.To make sure the model
is strong and works well with unseen data, it is crucial to use
additional evaluation metrics like validation error, test error, and
cross-validation. To lessen the likelihood of over-fitting, one could
also think about collecting more data or reducing the number of
hyper-parameters.

\textbf{QA4. What is the role of the lambda parameter in regularized
linear models such as Lasso or Ridge regression models? }

\emph{Answer:} Ridge and LASSO regression are both regularization
techniques used to prevent over-fitting and improve the generalization
of linear models. They work by adding a penalty term to the linear
regression objective function to shrink the magnitude of the coefficient
estimates towards zero. This helps to reduce the impact of irrelevant
features and avoid over-fitting. Lambda is basically a free parameter
which we can control.In L1 and L2 regularization whenever the theta
value gets bigger, the error will be bigger and the model will not
converge. So essentially here lambda plays an important role of
penalizing the higher values of theta. It makes sure that the theta
value does not go too high so they will remain very small. The higher
value of lambda leads to greater shrinkage of the coefficient estimates
towards zero, resulting in a simpler model with less variance and
potentially more bias. In LASSO regression, the penalty term is an L1
regularization penalty, which increases the objective function by the
absolute magnitude of the coefficient estimations. Some estimations of
the coefficients are exactly 0 as a result of this penalty.Whereas in
Ridge regression the penalty term is L2 regularization which increases
the objective function by the squared size of the coefficient
estimates.This penalty results in small but non-zero coefficient.

\textbf{PART B}

\textbf{QB1. Build a Lasso regression model to predict Sales based on
all other attributes (``Price'', ``Advertising'', ``Population'',
``Age'', ``Income'' and ``Education''). What is the best value of lambda
for such a lasso model? (Hint1: Do not forget to scale your input
attributes -- you can use the caret preprocess() function to scale and
center the data. Hint 2: glment library expect the input attributes to
be in the matrix format. You can use the as.matrix() function for
converting)}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#loading the required libraries}
\FunctionTok{library}\NormalTok{(}\StringTok{"ISLR"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Attaching package: 'dplyr'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:stats':
## 
##     filter, lag
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"glmnet"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: package 'glmnet' was built under R version 4.2.2
\end{verbatim}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## Warning: package 'Matrix' was built under R version 4.2.2
\end{verbatim}

\begin{verbatim}
## Loaded glmnet 4.1-6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"caret"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: ggplot2
\end{verbatim}

\begin{verbatim}
## Loading required package: lattice
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filtered\_dataset }\OtherTok{\textless{}{-}}\NormalTok{ Carseats }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\StringTok{"Sales"}\NormalTok{, }\StringTok{"Price"}\NormalTok{, }
\StringTok{"Advertising"}\NormalTok{,}\StringTok{"Population"}\NormalTok{,}\StringTok{"Age"}\NormalTok{,}\StringTok{"Income"}\NormalTok{,}\StringTok{"Education"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#scale and center data}
\NormalTok{dataset\_scaled }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(}\FunctionTok{preProcess}\NormalTok{(filtered\_dataset[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{],}\AttributeTok{method=}\FunctionTok{c}\NormalTok{(}\StringTok{"scale"}\NormalTok{,}\StringTok{"center"}\NormalTok{)),filtered\_dataset)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create design matrix and response vector}
\NormalTok{y}\OtherTok{\textless{}{-}}\NormalTok{ dataset\_scaled}\SpecialCharTok{$}\NormalTok{Sales}
\NormalTok{x}\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(dataset\_scaled[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#creating a sequence of values representing a range of lambda (λ) values}
\NormalTok{lambdas }\OtherTok{\textless{}{-}} \FunctionTok{exp}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\FunctionTok{log}\NormalTok{(}\DecValTok{100}\NormalTok{), }\FunctionTok{log}\NormalTok{(}\FloatTok{0.001}\NormalTok{), }\AttributeTok{length.out =} \DecValTok{61}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Lasso regression with cross{-}validation using the cv.glmnet() function with 10 fold cross validation}
\NormalTok{Lasso\_regression}\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(x,y,}\AttributeTok{alpha=}\DecValTok{1}\NormalTok{,}\AttributeTok{standardize=}\ConstantTok{TRUE}\NormalTok{,}\AttributeTok{nfolds =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Ploting cross{-}validation error as a function of lambda}
\FunctionTok{plot}\NormalTok{(Lasso\_regression)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ADM-ASSIGNMENT-1_files/figure-latex/unnamed-chunk-7-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Finding the lambda that gives minimum cross{-}validation error}
\NormalTok{best\_lambda}\OtherTok{\textless{}{-}}\NormalTok{Lasso\_regression}\SpecialCharTok{$}\NormalTok{lambda.min}
\NormalTok{best\_lambda}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008257196
\end{verbatim}

\textbf{QB2. What is the coefficient for the price (normalized)
attribute in the best model (i.e.~model with the optimal lambda)?}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#coefficient for price with best lambda}
\NormalTok{lasso\_coef}\OtherTok{\textless{}{-}}\FunctionTok{coef}\NormalTok{(Lasso\_regression,}\AttributeTok{s=}\NormalTok{best\_lambda)}
\NormalTok{lasso\_coef}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 7 x 1 sparse Matrix of class "dgCMatrix"
##                      s1
## (Intercept)  7.49632500
## Price       -1.34932264
## Advertising  0.82265121
## Population  -0.12455195
## Age         -0.78393966
## Income       0.28624250
## Education   -0.08686265
\end{verbatim}

\textbf{QB3. How many attributes remain in the model if lambda is set to
0.01? How that number changes if lambda is increased to 0.1? Do you
expect more variables to stay in the model (i.e., to have non-zero
coefficients) as we increase lambda?}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Fitting the Lasso model using lambda = 0.01}
\NormalTok{lassomodel}\FloatTok{.01}\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(x,y,}\AttributeTok{alpha=}\DecValTok{1}\NormalTok{,}\AttributeTok{lambda =} \FloatTok{0.01}\NormalTok{)}
\CommentTok{\#Finding the number of non{-}zero coefficients in the model when lambda=0.01}
\NormalTok{no\_attri}\FloatTok{.01} \OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{coef}\NormalTok{(lassomodel}\FloatTok{.01}\NormalTok{, }\AttributeTok{s =} \FloatTok{0.01}\NormalTok{) }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{)}
\NormalTok{no\_attri}\FloatTok{.01}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

\emph{All the attributes remain in the model when lambda is set to
0.01.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Fitting the Lasso model using lambda = 0.1}
\NormalTok{lassomodel}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(x,y, }\AttributeTok{alpha =}\DecValTok{1}\NormalTok{,}\AttributeTok{lambda=}\FloatTok{0.1}\NormalTok{)}
\CommentTok{\#Finding the number of non{-}zero coefficients in the model when lambda=0.1}
\NormalTok{no\_attri}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{coef}\NormalTok{(lassomodel}\FloatTok{.1}\NormalTok{, }\AttributeTok{s =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{!=} \DecValTok{0}\NormalTok{)}
\NormalTok{no\_attri}\FloatTok{.1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\emph{When lambda is increased to 0.1, two of the attributes are
removed.}

\textbf{QB4. Build an elastic-net model with alpha set to 0.6. What is
the best value of lambda for such a model?}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fitting the elastic{-}net model with alpha = 0.6 using cross{-}validation}
\NormalTok{elasticnet.model }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(x,y,}\AttributeTok{alpha =} \FloatTok{0.6}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(elasticnet.model, }\AttributeTok{xvar =} \StringTok{"lambda"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ADM-ASSIGNMENT-1_files/figure-latex/unnamed-chunk-12-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{cv.glmnet}\NormalTok{(x,y,}\AttributeTok{alpha=}\FloatTok{0.6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{ADM-ASSIGNMENT-1_files/figure-latex/unnamed-chunk-12-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Finding the best value of lambda that minimizes the cross{-}validation error}
\NormalTok{best\_lamda.el }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(x,y,}\AttributeTok{alpha=}\FloatTok{0.6}\NormalTok{)}

\NormalTok{EL }\OtherTok{\textless{}{-}}\NormalTok{ best\_lamda.el}\SpecialCharTok{$}\NormalTok{lambda.min}
\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Best lambda :"}\NormalTok{,EL))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Best lambda :0.00653806152801921"
\end{verbatim}

\end{document}
